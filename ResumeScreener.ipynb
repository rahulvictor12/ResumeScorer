{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T15:35:53.414775Z",
     "start_time": "2025-04-04T15:35:21.466399Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import warnings\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from io import BytesIO\n",
    "\n",
    "# Import your DI container and components\n",
    "from DependencyInjection.container import Container"
   ],
   "id": "fbc121e30a2defb3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rahul\\miniconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T15:35:53.436817Z",
     "start_time": "2025-04-04T15:35:53.414775Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize the container\n",
    "container = Container()\n",
    "\n",
    "def extract_resume_text(file):\n",
    "    try:\n",
    "        extracted_text = ''\n",
    "        if isinstance(file, str):\n",
    "            if not os.path.exists(file):\n",
    "                raise FileNotFoundError('File not found')\n",
    "\n",
    "            if file.split()[-1].endswith('.pdf'):\n",
    "                extractor = container.pdf_extractor()\n",
    "            elif file.split()[-1].endswith(('.doc', '.docx')):\n",
    "                extractor = container.word_extractor()\n",
    "            else:\n",
    "                return \"Error: Unsupported file format (only PDF/DOC/DOCX accepted)\"\n",
    "\n",
    "            extracted_text = extractor.extract_text_from_path(file)\n",
    "\n",
    "        elif isinstance(file, BytesIO) or hasattr(file, \"read\"):\n",
    "            file_name = getattr(file, \"name\").lower()\n",
    "            if file_name.endswith('.pdf'):\n",
    "                extractor = container.pdf_extractor()\n",
    "            elif file_name.endswith(('.doc', '.docx')):\n",
    "                extractor = container.word_extractor()\n",
    "            else:\n",
    "                return \"Error: Unsupported file format (only PDF/DOC/DOCX accepted)\"\n",
    "\n",
    "            extracted_text = extractor.extract_text_from_pdf_file(file)\n",
    "\n",
    "        if extracted_text.isspace():\n",
    "            return \"Error: No Text could be Extracted from file\"\n",
    "\n",
    "        return extracted_text\n",
    "\n",
    "    except Exception as e:\n",
    "        return f'Error: {e}'"
   ],
   "id": "371d24fe9ef0dbd0",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Why spaCy?\n",
    "More accurate tokenization (handles hyphenated words, contractions, and punctuation better).\n",
    "Built-in lemmatization (no need for additional libraries like NLTK's WordNet).\n",
    "Faster (optimized Cython backend).\n",
    "Scalable (supports custom pipelines for resume-specific terms).\n"
   ],
   "id": "324cdada366ceef3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T15:35:54.602420Z",
     "start_time": "2025-04-04T15:35:53.841994Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#  spaCy (better for resume parsing since it includes NER and POS out-of-the-box)\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def process_text_with_spacy(text):\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Preprocessing of Text:\n",
    "    #Tokenize the Text, Excluding Stop-words and Punctuations:\n",
    "    tokens = [token.text.lower() for token in doc if not token.is_stop and not token.is_punct and not token.is_space]\n",
    "\n",
    "    # Lemmatization:\n",
    "    lemmas = [token.lemma_.lower() for token in doc if not token.is_stop and not token.is_punct]\n",
    "\n",
    "    # Named Entity Recognition\n",
    "    entities = {ent.text: ent.label_ for ent in doc.ents}\n",
    "\n",
    "\n",
    "    return {\"tokens\": tokens, \"lemmas\": lemmas, \"entities\": entities}"
   ],
   "id": "d1ee43a65cfe9d5",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T15:35:54.674093Z",
     "start_time": "2025-04-04T15:35:54.612032Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Clean and Read the Resume and Description Data from the CSV's\n",
    "resumeDF = pd.read_csv('data/Resume.csv', nrows = 100)\n",
    "jdDF = pd.read_csv('data/fake_job_postings.csv', nrows = 100)"
   ],
   "id": "3eb55355146455e8",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T15:35:54.716220Z",
     "start_time": "2025-04-04T15:35:54.697127Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Inspect the Values of both the DataFrames.\n",
    "resumeDF.head()"
   ],
   "id": "1b72f3f330b9eb17",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         ID                                         Resume_str  \\\n",
       "0  16852973           HR ADMINISTRATOR/MARKETING ASSOCIATE\\...   \n",
       "1  22323967           HR SPECIALIST, US HR OPERATIONS      ...   \n",
       "2  33176873           HR DIRECTOR       Summary      Over 2...   \n",
       "3  27018550           HR SPECIALIST       Summary    Dedica...   \n",
       "4  17812897           HR MANAGER         Skill Highlights  ...   \n",
       "\n",
       "                                         Resume_html Category  \n",
       "0  <div class=\"fontsize fontface vmargins hmargin...       HR  \n",
       "1  <div class=\"fontsize fontface vmargins hmargin...       HR  \n",
       "2  <div class=\"fontsize fontface vmargins hmargin...       HR  \n",
       "3  <div class=\"fontsize fontface vmargins hmargin...       HR  \n",
       "4  <div class=\"fontsize fontface vmargins hmargin...       HR  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Resume_str</th>\n",
       "      <th>Resume_html</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16852973</td>\n",
       "      <td>HR ADMINISTRATOR/MARKETING ASSOCIATE\\...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargin...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22323967</td>\n",
       "      <td>HR SPECIALIST, US HR OPERATIONS      ...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargin...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33176873</td>\n",
       "      <td>HR DIRECTOR       Summary      Over 2...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargin...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27018550</td>\n",
       "      <td>HR SPECIALIST       Summary    Dedica...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargin...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17812897</td>\n",
       "      <td>HR MANAGER         Skill Highlights  ...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargin...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T15:35:54.790880Z",
     "start_time": "2025-04-04T15:35:54.774755Z"
    }
   },
   "cell_type": "code",
   "source": "jdDF.head()",
   "id": "86f572dd58319aba",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   job_id                                      title            location  \\\n",
       "0       1                           Marketing Intern    US, NY, New York   \n",
       "1       2  Customer Service - Cloud Video Production      NZ, , Auckland   \n",
       "2       3    Commissioning Machinery Assistant (CMA)       US, IA, Wever   \n",
       "3       4          Account Executive - Washington DC  US, DC, Washington   \n",
       "4       5                        Bill Review Manager  US, FL, Fort Worth   \n",
       "\n",
       "  department salary_range                                    company_profile  \\\n",
       "0  Marketing          NaN  We're Food52, and we've created a groundbreaki...   \n",
       "1    Success          NaN  90 Seconds, the worlds Cloud Video Production ...   \n",
       "2        NaN          NaN  Valor Services provides Workforce Solutions th...   \n",
       "3      Sales          NaN  Our passion for improving quality of life thro...   \n",
       "4        NaN          NaN  SpotSource Solutions LLC is a Global Human Cap...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Food52, a fast-growing, James Beard Award-winn...   \n",
       "1  Organised - Focused - Vibrant - Awesome!Do you...   \n",
       "2  Our client, located in Houston, is actively se...   \n",
       "3  THE COMPANY: ESRI – Environmental Systems Rese...   \n",
       "4  JOB TITLE: Itemization Review ManagerLOCATION:...   \n",
       "\n",
       "                                        requirements  \\\n",
       "0  Experience with content management systems a m...   \n",
       "1  What we expect from you:Your key responsibilit...   \n",
       "2  Implement pre-commissioning and commissioning ...   \n",
       "3  EDUCATION: Bachelor’s or Master’s in GIS, busi...   \n",
       "4  QUALIFICATIONS:RN license in the State of Texa...   \n",
       "\n",
       "                                            benefits  telecommuting  \\\n",
       "0                                                NaN              0   \n",
       "1  What you will get from usThrough being part of...              0   \n",
       "2                                                NaN              0   \n",
       "3  Our culture is anything but corporate—we have ...              0   \n",
       "4                              Full Benefits Offered              0   \n",
       "\n",
       "   has_company_logo  has_questions employment_type required_experience  \\\n",
       "0                 1              0           Other          Internship   \n",
       "1                 1              0       Full-time      Not Applicable   \n",
       "2                 1              0             NaN                 NaN   \n",
       "3                 1              0       Full-time    Mid-Senior level   \n",
       "4                 1              1       Full-time    Mid-Senior level   \n",
       "\n",
       "  required_education                   industry              function  \\\n",
       "0                NaN                        NaN             Marketing   \n",
       "1                NaN  Marketing and Advertising      Customer Service   \n",
       "2                NaN                        NaN                   NaN   \n",
       "3  Bachelor's Degree          Computer Software                 Sales   \n",
       "4  Bachelor's Degree     Hospital & Health Care  Health Care Provider   \n",
       "\n",
       "   fraudulent  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>title</th>\n",
       "      <th>location</th>\n",
       "      <th>department</th>\n",
       "      <th>salary_range</th>\n",
       "      <th>company_profile</th>\n",
       "      <th>description</th>\n",
       "      <th>requirements</th>\n",
       "      <th>benefits</th>\n",
       "      <th>telecommuting</th>\n",
       "      <th>has_company_logo</th>\n",
       "      <th>has_questions</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>required_experience</th>\n",
       "      <th>required_education</th>\n",
       "      <th>industry</th>\n",
       "      <th>function</th>\n",
       "      <th>fraudulent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Marketing Intern</td>\n",
       "      <td>US, NY, New York</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We're Food52, and we've created a groundbreaki...</td>\n",
       "      <td>Food52, a fast-growing, James Beard Award-winn...</td>\n",
       "      <td>Experience with content management systems a m...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Other</td>\n",
       "      <td>Internship</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Customer Service - Cloud Video Production</td>\n",
       "      <td>NZ, , Auckland</td>\n",
       "      <td>Success</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90 Seconds, the worlds Cloud Video Production ...</td>\n",
       "      <td>Organised - Focused - Vibrant - Awesome!Do you...</td>\n",
       "      <td>What we expect from you:Your key responsibilit...</td>\n",
       "      <td>What you will get from usThrough being part of...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Marketing and Advertising</td>\n",
       "      <td>Customer Service</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Commissioning Machinery Assistant (CMA)</td>\n",
       "      <td>US, IA, Wever</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Valor Services provides Workforce Solutions th...</td>\n",
       "      <td>Our client, located in Houston, is actively se...</td>\n",
       "      <td>Implement pre-commissioning and commissioning ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Account Executive - Washington DC</td>\n",
       "      <td>US, DC, Washington</td>\n",
       "      <td>Sales</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our passion for improving quality of life thro...</td>\n",
       "      <td>THE COMPANY: ESRI – Environmental Systems Rese...</td>\n",
       "      <td>EDUCATION: Bachelor’s or Master’s in GIS, busi...</td>\n",
       "      <td>Our culture is anything but corporate—we have ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>Bachelor's Degree</td>\n",
       "      <td>Computer Software</td>\n",
       "      <td>Sales</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Bill Review Manager</td>\n",
       "      <td>US, FL, Fort Worth</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SpotSource Solutions LLC is a Global Human Cap...</td>\n",
       "      <td>JOB TITLE: Itemization Review ManagerLOCATION:...</td>\n",
       "      <td>QUALIFICATIONS:RN license in the State of Texa...</td>\n",
       "      <td>Full Benefits Offered</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>Bachelor's Degree</td>\n",
       "      <td>Hospital &amp; Health Care</td>\n",
       "      <td>Health Care Provider</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T15:35:54.948933Z",
     "start_time": "2025-04-04T15:35:54.899186Z"
    }
   },
   "cell_type": "code",
   "source": [
    "resumeDF.info()\n",
    "# Obbservations:\n",
    "# No Null Values Present"
   ],
   "id": "fdf39079e06e1b20",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   ID           100 non-null    int64 \n",
      " 1   Resume_str   100 non-null    object\n",
      " 2   Resume_html  100 non-null    object\n",
      " 3   Category     100 non-null    object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 3.3+ KB\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T15:35:55.063560Z",
     "start_time": "2025-04-04T15:35:55.045163Z"
    }
   },
   "cell_type": "code",
   "source": "jdDF.info()",
   "id": "49c1147a65d1d84c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 18 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   job_id               100 non-null    int64 \n",
      " 1   title                100 non-null    object\n",
      " 2   location             100 non-null    object\n",
      " 3   department           27 non-null     object\n",
      " 4   salary_range         13 non-null     object\n",
      " 5   company_profile      88 non-null     object\n",
      " 6   description          100 non-null    object\n",
      " 7   requirements         89 non-null     object\n",
      " 8   benefits             54 non-null     object\n",
      " 9   telecommuting        100 non-null    int64 \n",
      " 10  has_company_logo     100 non-null    int64 \n",
      " 11  has_questions        100 non-null    int64 \n",
      " 12  employment_type      83 non-null     object\n",
      " 13  required_experience  61 non-null     object\n",
      " 14  required_education   67 non-null     object\n",
      " 15  industry             78 non-null     object\n",
      " 16  function             67 non-null     object\n",
      " 17  fraudulent           100 non-null    int64 \n",
      "dtypes: int64(5), object(13)\n",
      "memory usage: 14.2+ KB\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T15:35:55.216224Z",
     "start_time": "2025-04-04T15:35:55.208966Z"
    }
   },
   "cell_type": "code",
   "source": "jdDF['requirements'] = jdDF['requirements'].fillna('').astype(str)",
   "id": "664fe3e2e18309d3",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T15:35:55.381504Z",
     "start_time": "2025-04-04T15:35:55.354452Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Extract the Resumes and JD's\n",
    "resume_text = []\n",
    "jd_text = []\n",
    "\n",
    "for i, row in resumeDF.iterrows():\n",
    "    text = row['Resume_str'] + '\\n\\n'\n",
    "    resume_text.append(text)\n",
    "\n",
    "for i , row in jdDF.iterrows():\n",
    "    text = row['title'] + '\\n\\n' + row['description'] + '\\n\\n' + row['requirements']\n",
    "    jd_text.append(text)"
   ],
   "id": "964ce7833b2f4960",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "if __name__ == '__main__':\n",
    "file_path = \"data\"\n",
    "\n",
    "Process the file\n",
    "resume = extract_resume_text(file_path)\n",
    "\n",
    "Print results\n",
    "if resume.startswith(\"Error\"):\n",
    "    print(resume)\n",
    "else:\n",
    "    print(\"Successfully extracted text:\\n\")\n",
    "    print(resume)\n",
    "    # To Tackle the Memory Error while processing the large texts we divide the text into chunks.\n",
    "\n",
    "def process_text_in_chunks(texts, batch_size):\n",
    "    results = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_text = \" \".join(texts[i : i + batch_size])\n",
    "        results.append(process_text_with_spacy(batch_text))\n",
    "    return results\n"
   ],
   "id": "3783172956e3d848"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T15:36:13.265686Z",
     "start_time": "2025-04-04T15:35:56.550251Z"
    }
   },
   "cell_type": "code",
   "source": "resume_processed = [process_text_with_spacy(text) for text in resume_text]",
   "id": "eeeaa483c4674e93",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T15:36:17.460164Z",
     "start_time": "2025-04-04T15:36:13.281229Z"
    }
   },
   "cell_type": "code",
   "source": "description_processed = [process_text_with_spacy(text) for text in jd_text]",
   "id": "2eb853ddbac99da7",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T15:36:17.546437Z",
     "start_time": "2025-04-04T15:36:17.538604Z"
    }
   },
   "cell_type": "code",
   "source": "model = container.ml_models()",
   "id": "26d8d397d97c58e3",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T15:36:17.587068Z",
     "start_time": "2025-04-04T15:36:17.578317Z"
    }
   },
   "cell_type": "code",
   "source": [
    "resume_tokens_list = [doc[\"tokens\"] for doc in resume_processed]\n",
    "jd_tokens_list = [doc[\"tokens\"] for doc in description_processed]\n",
    "all_resume_tokens = [token for tokens in resume_tokens_list for token in tokens]\n",
    "all_jd_tokens = [token for tokens in jd_tokens_list for token in tokens]\n",
    "\n",
    "# word_weights = model.load_TfIdfVectorizer(all_resume_tokens, all_jd_tokens)\n",
    "# print(word_weights)"
   ],
   "id": "6dc1634cc9124917",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "'''\n",
    "resume_embeddings = []\n",
    "jd_embeddings = []\n",
    "for tokens in resume_tokens_list:\n",
    "    embed = model.get_weighted_embeddings_from_sbert(tokens, word_weights, sbert_model)\n",
    "    resume_embeddings.append(embed)\n",
    "\n",
    "for tokens in jd_tokens_list:\n",
    "    embed = model.get_weighted_embeddings_from_sbert(tokens, word_weights, sbert_model)\n",
    "    jd_embeddings.append(embed)\n",
    "\n",
    "resume_embeddings = np.array(resume_embeddings)\n",
    "jd_embeddings = np.array(jd_embeddings)\n",
    "'''"
   ],
   "id": "6be568a4b55c37f6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T15:36:21.899550Z",
     "start_time": "2025-04-04T15:36:17.587068Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Load the S-BERT Model to get the Embeddings.\n",
    "sbert_model = model.load_sbert_model()"
   ],
   "id": "a6b80fbadf52eebf",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nresume_embeddings = []\\njd_embeddings = []\\nfor tokens in resume_tokens_list:\\n    embed = model.get_weighted_embeddings_from_sbert(tokens, word_weights, sbert_model)\\n    resume_embeddings.append(embed)\\n\\nfor tokens in jd_tokens_list:\\n    embed = model.get_weighted_embeddings_from_sbert(tokens, word_weights, sbert_model)\\n    jd_embeddings.append(embed)\\n\\nresume_embeddings = np.array(resume_embeddings)\\njd_embeddings = np.array(jd_embeddings)\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T15:36:21.923016Z",
     "start_time": "2025-04-04T15:36:21.916306Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train the Resume Scoring Model\n",
    "# rf_model = model.train_scoring_model(resume_embeddings, jd_embeddings)"
   ],
   "id": "9e3c1f0a932b639b",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Testing the Prediction Capacity of the Model:\n",
    "jd_new_path = \"data/Machine_Learning_Engineer_Job_Description.pdf\"\n",
    "resume_new_path = \"data/Rahul Victor Sunkara_UpdatedResume.pdf\"\n",
    "\n",
    "Extract the Text\n",
    "resume_text_new = extract_resume_text(resume_new_path)\n",
    "jd_text_new = extract_resume_text(jd_new_path)  # Try Renaming to extract_text_from_pdf\n",
    "\n",
    "Preprocess\n",
    "resume_text_input = \" \".join(process_text_with_spacy(resume_text_new)[\"lemmas\"])\n",
    "jd_text_input = \" \".join(process_text_with_spacy(jd_text_new)[\"lemmas\"])\n",
    "\n",
    "Calculate matching percentage\n",
    "match_percent = model.calculate_matching_score(jd_new_path, resume_new_path, sbert_model)\n",
    "print(f\"\\nMatching Percentage: {match_percent:.2f}%\")\n"
   ],
   "id": "7c08f20b2325eaed"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import streamlit as st\n",
    "from io import BytesIO\n",
    "\n",
    "# FrontEnd Webpage using Streamlit.\n",
    "st.set_page_config(page_title=\"Resume and JD Matching\", layout=\"wide\")\n",
    "st.title(\"Resume Screener\")\n",
    "\n",
    "# Get the Job Description Text\n",
    "jd_text_new = st.text_area(\"Input Job Description\", height=300)\n",
    "\n",
    "# Upload Resume\n",
    "resume_file = st.file_uploader('Upload your Resume File in PDF / Docx Format.', type=['pdf', 'doc', 'docx'])\n",
    "\n",
    "if st.button(\"Match Resume\"):\n",
    "    if not jd_text or not resume_file:\n",
    "        st.warning(\"Please upload your Resume File and Job Description\")\n",
    "    else:\n",
    "        with st.spinner('Processing...'):\n",
    "            resume_text_new = extract_resume_text(resume_file)\n",
    "            resume_text_input = \" \".join(process_text_with_spacy(resume_text_new)[\"lemmas\"])\n",
    "            jd_text_input = \" \".join(process_text_with_spacy(jd_text_new)[\"lemmas\"])\n",
    "\n",
    "            # Calculate matching percentage\n",
    "            match_percent = model.calculate_matching_score(jd_text, resume_text, sbert_model)\n",
    "\n",
    "        st.success(\" Matching Completed!\")\n",
    "        st.markdown(f\" Matching Score: `{match_percent:.2f}%`\")\n",
    "\n",
    "        # Optional: show as progress bar\n",
    "        st.progress(min(match_percent / 100, 1.0))"
   ],
   "id": "d1628bd2c1085bcc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
